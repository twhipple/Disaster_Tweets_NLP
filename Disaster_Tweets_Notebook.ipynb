{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Disaster\n",
    "* Geophysical (e.g. Earthquakes, Landslides, Tsunamis and Volcanic Activity)\n",
    "* Hydrological (e.g. Avalanches and Floods)\n",
    "* Climatological (e.g. Extreme Temperatures, Drought and Wildfires)\n",
    "* Meteorological (e.g. Cyclones and Storms/Wave Surges)\n",
    "* Biological (e.g. Disease Epidemics and Insect/Animal Plagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_list = ['tsunami', 'disasters', 'volcano', 'tornado', 'avalanche', 'earthquake', \n",
    "                 'blizzard', 'drought', 'bushfire', 'tremor', 'dust storm', 'storm', 'magma',\n",
    "                 'twister', 'windstorm', 'heat wave', 'cyclone', 'forest fire', 'flood', 'fire',\n",
    "                 'hailstorm', 'lava', 'lightning', 'high-pressure', 'hail', 'hurricane', \n",
    "                 'seismic', 'erosion', 'whirlpool', 'Richter scale', 'whirlwind', 'dark cloud', \n",
    "                 'thunderstorm', 'barometer', 'gale', 'blackout', 'gust', 'force', 'low-pressure',\n",
    "                 'volt', 'snowstorm', 'rainstorm', 'storm', 'nimbus', 'violent storm', 'sandstorm',\n",
    "                 'casualty', 'Beaufort scale', 'fatal', 'fatality', 'cumulonimbus', 'death', 'lost',\n",
    "                 'destruction', 'tension', 'cataclysm', 'damage', 'uproot', 'underground', 'destroy',\n",
    "                 'arsonist', 'wind scale', 'arson', 'rescue', 'permafrost', 'fault', 'drown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target\n",
       "count   7613.000000  7613.00000\n",
       "mean    5441.934848     0.42966\n",
       "std     3137.116090     0.49506\n",
       "min        1.000000     0.00000\n",
       "25%     2734.000000     0.00000\n",
       "50%     5408.000000     0.00000\n",
       "75%     8146.000000     1.00000\n",
       "max    10873.000000     1.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "body%20bags              41\n",
       "sinking                  41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A space is assigned number 32, which is 20 in hexadecimal. When you see “%20,” it represents a space in an encoded URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7552"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9919873899908052"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.count()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920318725099602"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keyword.count()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-755c9ed50abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"([a-zA-Z]+(?:'[a-z]+)?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_tokens_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mregexp_tokenize\u001b[0;34m(text, pattern, gaps, discard_empty, flags)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[1;32m    215\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscard_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# If our regexp matches tokens, use re.findall:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Remove all hyphens and quotes \n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "train['text_tokens_raw'] = nltk.regexp_tokenize(train['text'], pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train.text.head()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13,000 people receive #wildfires evacuation orders in California '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people', 'receive', 'wildfires', 'evacuation', 'orders', 'in', 'California']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "token_pattern = nltk.regexp_tokenize(sample[3], pattern)\n",
    "token_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people', 'receive', 'wildfires', 'evacuation', 'orders', 'in', 'california']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pattern_lower = [word.lower() for word in token_pattern]\n",
    "token_pattern_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people', 'receive', 'wildfires', 'evacuation', 'orders', 'california']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pattern_lower_stopless = [word for word in token_pattern_lower if word not in stopwords_list]\n",
    "token_pattern_lower_stopless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 7613)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(train.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "new_column = []\n",
    "\n",
    "for i in range(len(train.text)):\n",
    "    token_pattern = nltk.regexp_tokenize(train.text[i], pattern)\n",
    "    token_pattern_lower = [word.lower() for word in token_pattern]\n",
    "    token_pattern_lower_stopless = [word for word in token_pattern_lower if word not in stopwords_list]\n",
    "    new_column += token_pattern_lower_stopless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deeds',\n",
       " 'reason',\n",
       " 'earthquake',\n",
       " 'may',\n",
       " 'allah',\n",
       " 'forgive',\n",
       " 'us',\n",
       " 'forest',\n",
       " 'fire',\n",
       " 'near',\n",
       " 'la',\n",
       " 'ronge',\n",
       " 'sask',\n",
       " 'canada',\n",
       " 'residents',\n",
       " 'asked',\n",
       " 'shelter',\n",
       " 'place',\n",
       " 'notified',\n",
       " 'officers',\n",
       " 'evacuation',\n",
       " 'shelter',\n",
       " 'place',\n",
       " 'orders',\n",
       " 'expected',\n",
       " 'people',\n",
       " 'receive',\n",
       " 'wildfires',\n",
       " 'evacuation',\n",
       " 'orders',\n",
       " 'california',\n",
       " 'got',\n",
       " 'sent',\n",
       " 'photo',\n",
       " 'ruby',\n",
       " 'alaska',\n",
       " 'smoke',\n",
       " 'wildfires',\n",
       " 'pours',\n",
       " 'school',\n",
       " 'rockyfire',\n",
       " 'update',\n",
       " 'california',\n",
       " 'hwy',\n",
       " 'closed',\n",
       " 'directions',\n",
       " 'due',\n",
       " 'lake',\n",
       " 'county',\n",
       " 'fire',\n",
       " 'cafire',\n",
       " 'wildfires',\n",
       " 'flood',\n",
       " 'disaster',\n",
       " 'heavy',\n",
       " 'rain',\n",
       " 'causes',\n",
       " 'flash',\n",
       " 'flooding',\n",
       " 'streets',\n",
       " 'manitou',\n",
       " 'colorado',\n",
       " 'springs',\n",
       " 'areas',\n",
       " \"i'm\",\n",
       " 'top',\n",
       " 'hill',\n",
       " 'see',\n",
       " 'fire',\n",
       " 'woods',\n",
       " \"there's\",\n",
       " 'emergency',\n",
       " 'evacuation',\n",
       " 'happening',\n",
       " 'building',\n",
       " 'across',\n",
       " 'street',\n",
       " \"i'm\",\n",
       " 'afraid',\n",
       " 'tornado',\n",
       " 'coming',\n",
       " 'area',\n",
       " 'three',\n",
       " 'people',\n",
       " 'died',\n",
       " 'heat',\n",
       " 'wave',\n",
       " 'far',\n",
       " 'haha',\n",
       " 'south',\n",
       " 'tampa',\n",
       " 'getting',\n",
       " 'flooded',\n",
       " 'hah',\n",
       " 'wait',\n",
       " 'second',\n",
       " 'live',\n",
       " 'south',\n",
       " 'tampa',\n",
       " 'gonna',\n",
       " 'gonna',\n",
       " 'fvck',\n",
       " 'flooding',\n",
       " 'raining',\n",
       " 'flooding',\n",
       " 'florida',\n",
       " 'tampabay',\n",
       " 'tampa',\n",
       " 'days',\n",
       " \"i've\",\n",
       " 'lost',\n",
       " 'count',\n",
       " 'flood',\n",
       " 'bago',\n",
       " 'myanmar',\n",
       " 'arrived',\n",
       " 'bago',\n",
       " 'damage',\n",
       " 'school',\n",
       " 'bus',\n",
       " 'multi',\n",
       " 'car',\n",
       " 'crash',\n",
       " 'breaking',\n",
       " \"what's\",\n",
       " 'man',\n",
       " 'love',\n",
       " 'fruits',\n",
       " 'summer',\n",
       " 'lovely',\n",
       " 'car',\n",
       " 'fast',\n",
       " 'goooooooaaaaaal',\n",
       " 'ridiculous',\n",
       " 'london',\n",
       " 'cool',\n",
       " 'love',\n",
       " 'skiing',\n",
       " 'wonderful',\n",
       " 'day',\n",
       " 'looooool',\n",
       " 'way',\n",
       " \"can't\",\n",
       " 'eat',\n",
       " 'shit',\n",
       " 'nyc',\n",
       " 'last',\n",
       " 'week',\n",
       " 'love',\n",
       " 'girlfriend',\n",
       " 'cooool',\n",
       " 'like',\n",
       " 'pasta',\n",
       " 'end',\n",
       " 'bbcmtd',\n",
       " 'wholesale',\n",
       " 'markets',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'lhyxeohy',\n",
       " 'c',\n",
       " 'always',\n",
       " 'try',\n",
       " 'bring',\n",
       " 'heavy',\n",
       " 'metal',\n",
       " 'rt',\n",
       " 'http',\n",
       " 'co',\n",
       " 'yao',\n",
       " 'e',\n",
       " 'xngw',\n",
       " 'africanbaze',\n",
       " 'breaking',\n",
       " 'news',\n",
       " 'nigeria',\n",
       " 'flag',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'aba',\n",
       " 'http',\n",
       " 'co',\n",
       " 'nndbgwyei',\n",
       " 'crying',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'plus',\n",
       " 'side',\n",
       " 'look',\n",
       " 'sky',\n",
       " 'last',\n",
       " 'night',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'qqsmshaj',\n",
       " 'n',\n",
       " 'phdsquares',\n",
       " 'mufc',\n",
       " \"they've\",\n",
       " 'built',\n",
       " 'much',\n",
       " 'hype',\n",
       " 'around',\n",
       " 'new',\n",
       " 'acquisitions',\n",
       " 'doubt',\n",
       " 'set',\n",
       " 'epl',\n",
       " 'ablaze',\n",
       " 'season',\n",
       " 'inec',\n",
       " 'office',\n",
       " 'abia',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'imaomknna',\n",
       " 'barbados',\n",
       " 'bridgetown',\n",
       " 'jamaica',\n",
       " 'two',\n",
       " 'cars',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'santa',\n",
       " 'cruz',\n",
       " 'head',\n",
       " 'st',\n",
       " 'elizabeth',\n",
       " 'police',\n",
       " 'superintende',\n",
       " 'http',\n",
       " 'co',\n",
       " 'wdueaj',\n",
       " 'q',\n",
       " 'j',\n",
       " 'ablaze',\n",
       " 'lord',\n",
       " 'check',\n",
       " 'http',\n",
       " 'co',\n",
       " 'roi',\n",
       " 'nsmejj',\n",
       " 'http',\n",
       " 'co',\n",
       " 'tj',\n",
       " 'zjin',\n",
       " 'http',\n",
       " 'co',\n",
       " 'yduixefipe',\n",
       " 'http',\n",
       " 'co',\n",
       " 'lxtjc',\n",
       " 'kls',\n",
       " 'nsfw',\n",
       " 'outside',\n",
       " 'ablaze',\n",
       " 'alive',\n",
       " 'dead',\n",
       " 'inside',\n",
       " 'awesome',\n",
       " 'time',\n",
       " 'visiting',\n",
       " 'cfc',\n",
       " 'head',\n",
       " 'office',\n",
       " 'ancop',\n",
       " 'site',\n",
       " 'ablaze',\n",
       " 'thanks',\n",
       " 'tita',\n",
       " 'vida',\n",
       " 'taking',\n",
       " 'care',\n",
       " 'us',\n",
       " 'soooo',\n",
       " 'pumped',\n",
       " 'ablaze',\n",
       " 'southridgelife',\n",
       " 'wanted',\n",
       " 'set',\n",
       " 'chicago',\n",
       " 'ablaze',\n",
       " 'preaching',\n",
       " 'hotel',\n",
       " 'http',\n",
       " 'co',\n",
       " 'qknbfofx',\n",
       " 'gained',\n",
       " 'followers',\n",
       " 'last',\n",
       " 'week',\n",
       " 'know',\n",
       " 'stats',\n",
       " 'grow',\n",
       " 'http',\n",
       " 'co',\n",
       " 'tiyulif',\n",
       " 'c',\n",
       " 'west',\n",
       " 'burned',\n",
       " 'thousands',\n",
       " 'wildfires',\n",
       " 'ablaze',\n",
       " 'california',\n",
       " 'alone',\n",
       " 'http',\n",
       " 'co',\n",
       " 'vl',\n",
       " 'tbr',\n",
       " 'wbr',\n",
       " 'building',\n",
       " 'perfect',\n",
       " 'tracklist',\n",
       " 'life',\n",
       " 'leave',\n",
       " 'streets',\n",
       " 'ablaze',\n",
       " 'check',\n",
       " 'http',\n",
       " 'co',\n",
       " 'roi',\n",
       " 'nsmejj',\n",
       " 'http',\n",
       " 'co',\n",
       " 'tj',\n",
       " 'zjin',\n",
       " 'http',\n",
       " 'co',\n",
       " 'yduixefipe',\n",
       " 'http',\n",
       " 'co',\n",
       " 'lxtjc',\n",
       " 'kls',\n",
       " 'nsfw',\n",
       " 'first',\n",
       " 'night',\n",
       " 'retainers',\n",
       " 'quite',\n",
       " 'weird',\n",
       " 'better',\n",
       " 'get',\n",
       " 'used',\n",
       " 'wear',\n",
       " 'every',\n",
       " 'single',\n",
       " 'night',\n",
       " 'next',\n",
       " 'year',\n",
       " 'least',\n",
       " 'deputies',\n",
       " 'man',\n",
       " 'shot',\n",
       " 'brighton',\n",
       " 'home',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'gwnrhmso',\n",
       " 'k',\n",
       " 'man',\n",
       " 'wife',\n",
       " 'get',\n",
       " 'six',\n",
       " 'years',\n",
       " 'jail',\n",
       " 'setting',\n",
       " 'ablaze',\n",
       " 'niece',\n",
       " 'http',\n",
       " 'co',\n",
       " 'ev',\n",
       " 'ahoucza',\n",
       " 'santa',\n",
       " 'cruz',\n",
       " 'head',\n",
       " 'st',\n",
       " 'elizabeth',\n",
       " 'police',\n",
       " 'superintendent',\n",
       " 'lanford',\n",
       " 'salmon',\n",
       " 'r',\n",
       " 'http',\n",
       " 'co',\n",
       " 'vplr',\n",
       " 'hka',\n",
       " 'u',\n",
       " 'http',\n",
       " 'co',\n",
       " 'sxhw',\n",
       " 'tnnlf',\n",
       " 'police',\n",
       " 'arsonist',\n",
       " 'deliberately',\n",
       " 'set',\n",
       " 'black',\n",
       " 'church',\n",
       " 'north',\n",
       " 'carolina',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'pcxarbh',\n",
       " 'noches',\n",
       " 'el',\n",
       " 'bestia',\n",
       " 'alexis',\n",
       " 'sanchez',\n",
       " 'happy',\n",
       " 'see',\n",
       " 'teammates',\n",
       " 'training',\n",
       " 'hard',\n",
       " 'goodnight',\n",
       " 'gunners',\n",
       " 'http',\n",
       " 'co',\n",
       " 'uc',\n",
       " 'j',\n",
       " 'jhvgr',\n",
       " 'kurds',\n",
       " 'trampling',\n",
       " 'turkmen',\n",
       " 'flag',\n",
       " 'later',\n",
       " 'set',\n",
       " 'ablaze',\n",
       " 'others',\n",
       " 'vandalized',\n",
       " 'offices',\n",
       " 'turkmen',\n",
       " 'front',\n",
       " 'diyala',\n",
       " 'http',\n",
       " 'co',\n",
       " 'izfdyc',\n",
       " 'cg',\n",
       " 'truck',\n",
       " 'ablaze',\n",
       " 'r',\n",
       " 'voortrekker',\n",
       " 'ave',\n",
       " 'outside',\n",
       " 'tambo',\n",
       " 'intl',\n",
       " 'cargo',\n",
       " 'section',\n",
       " 'http',\n",
       " 'co',\n",
       " 'kscqkfkkf',\n",
       " 'set',\n",
       " 'hearts',\n",
       " 'ablaze',\n",
       " 'every',\n",
       " 'city',\n",
       " 'gift',\n",
       " 'every',\n",
       " 'skyline',\n",
       " 'like',\n",
       " 'kiss',\n",
       " 'upon',\n",
       " 'lips',\n",
       " 'https',\n",
       " 'co',\n",
       " 'cyompz',\n",
       " 'z',\n",
       " 'sky',\n",
       " 'ablaze',\n",
       " 'tonight',\n",
       " 'los',\n",
       " 'angeles',\n",
       " \"i'm\",\n",
       " 'expecting',\n",
       " 'ig',\n",
       " 'fb',\n",
       " 'filled',\n",
       " 'sunset',\n",
       " 'shots',\n",
       " 'know',\n",
       " 'peeps',\n",
       " 'west',\n",
       " 'burned',\n",
       " 'thousands',\n",
       " 'wildfires',\n",
       " 'ablaze',\n",
       " 'california',\n",
       " 'alone',\n",
       " 'http',\n",
       " 'co',\n",
       " 'icsjgz',\n",
       " 'te',\n",
       " 'climate',\n",
       " 'energy',\n",
       " 'http',\n",
       " 'co',\n",
       " 'fxmn',\n",
       " 'l',\n",
       " 'bd',\n",
       " 'revel',\n",
       " 'wmv',\n",
       " 'videos',\n",
       " 'means',\n",
       " 'mac',\n",
       " 'farewell',\n",
       " 'ablaze',\n",
       " 'wmv',\n",
       " 'en',\n",
       " 'route',\n",
       " 'dvd',\n",
       " 'gtxrwm',\n",
       " 'progressive',\n",
       " 'greetings',\n",
       " 'month',\n",
       " 'students',\n",
       " 'would',\n",
       " 'set',\n",
       " 'pens',\n",
       " 'ablaze',\n",
       " 'torch',\n",
       " 'publications',\n",
       " 'http',\n",
       " 'co',\n",
       " 'fxpixqujt',\n",
       " 'rene',\n",
       " 'ablaze',\n",
       " 'amp',\n",
       " 'jacinta',\n",
       " 'secret',\n",
       " 'k',\n",
       " 'fallen',\n",
       " 'skies',\n",
       " 'edit',\n",
       " 'mar',\n",
       " 'https',\n",
       " 'co',\n",
       " 'mlmsuzv',\n",
       " 'z',\n",
       " 'navista',\n",
       " 'steve',\n",
       " 'fires',\n",
       " 'something',\n",
       " 'else',\n",
       " 'california',\n",
       " 'tinderbox',\n",
       " 'clown',\n",
       " 'setting',\n",
       " 'hood',\n",
       " 'ablaze',\n",
       " 'news',\n",
       " 'nowplaying',\n",
       " 'rene',\n",
       " 'ablaze',\n",
       " 'amp',\n",
       " 'ian',\n",
       " 'buff',\n",
       " 'magnitude',\n",
       " 'http',\n",
       " 'co',\n",
       " 'av',\n",
       " 'jsjfftc',\n",
       " 'edm',\n",
       " 'nxwestmidlands',\n",
       " 'huge',\n",
       " 'fire',\n",
       " 'wholesale',\n",
       " 'markets',\n",
       " 'ablaze',\n",
       " 'http',\n",
       " 'co',\n",
       " 'rwzbfvnxer',\n",
       " 'ablaze',\n",
       " 'time',\n",
       " 'talk',\n",
       " 'go',\n",
       " 'know',\n",
       " 'make',\n",
       " 'due',\n",
       " 'work',\n",
       " \"can't\",\n",
       " 'kids',\n",
       " 'cuz',\n",
       " 'got',\n",
       " 'bicycle',\n",
       " 'accident',\n",
       " 'amp',\n",
       " 'split',\n",
       " 'testicles',\n",
       " 'impossible',\n",
       " 'kids',\n",
       " 'michael',\n",
       " 'father',\n",
       " 'accident',\n",
       " 'w',\n",
       " 'nashvilletraffic',\n",
       " 'traffic',\n",
       " 'moving',\n",
       " 'slower',\n",
       " 'usual',\n",
       " 'https',\n",
       " 'co',\n",
       " 'ghk',\n",
       " 'egj',\n",
       " 'accident',\n",
       " 'center',\n",
       " 'lane',\n",
       " 'blocked',\n",
       " 'santaclara',\n",
       " 'us',\n",
       " 'nb',\n",
       " 'great',\n",
       " 'america',\n",
       " 'pkwy',\n",
       " 'bayarea',\n",
       " 'traffic',\n",
       " 'http',\n",
       " 'co',\n",
       " 'pmlohzurwr',\n",
       " 'http',\n",
       " 'co',\n",
       " 'gkye',\n",
       " 'gjtk',\n",
       " 'personalinjury',\n",
       " 'accident',\n",
       " 'summer',\n",
       " 'read',\n",
       " 'advice',\n",
       " 'amp',\n",
       " 'see',\n",
       " 'solicitor',\n",
       " 'help',\n",
       " 'otleyhour',\n",
       " 'stlouis',\n",
       " 'caraccidentlawyer',\n",
       " 'speeding',\n",
       " 'among',\n",
       " 'top',\n",
       " 'causes',\n",
       " 'teen',\n",
       " 'accidents',\n",
       " 'https',\n",
       " 'co',\n",
       " 'k',\n",
       " 'zomof',\n",
       " 'https',\n",
       " 'co',\n",
       " 'kxvm',\n",
       " 'cba',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'tee',\n",
       " 'reported',\n",
       " 'motor',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'curry',\n",
       " 'herman',\n",
       " 'rd',\n",
       " 'near',\n",
       " 'stephenson',\n",
       " 'involving',\n",
       " 'overturned',\n",
       " 'vehicle',\n",
       " 'please',\n",
       " 'use',\n",
       " 'http',\n",
       " 'co',\n",
       " 'ybjezkurw',\n",
       " 'bigrigradio',\n",
       " 'live',\n",
       " 'accident',\n",
       " 'awareness',\n",
       " 'mile',\n",
       " 'marker',\n",
       " 'south',\n",
       " 'mooresville',\n",
       " 'iredell',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'ramp',\n",
       " 'closed',\n",
       " 'pm',\n",
       " 'rt',\n",
       " 'sleepjunkies',\n",
       " 'sleeping',\n",
       " 'pills',\n",
       " 'double',\n",
       " 'risk',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'http',\n",
       " 'co',\n",
       " 'nm',\n",
       " 'fict',\n",
       " 'accident',\n",
       " 'knew',\n",
       " 'gon',\n",
       " 'happen',\n",
       " 'https',\n",
       " 'co',\n",
       " 'ysxun',\n",
       " 'vceh',\n",
       " 'traffic',\n",
       " 'accident',\n",
       " 'n',\n",
       " 'cabrillo',\n",
       " 'hwy',\n",
       " 'magellan',\n",
       " 'av',\n",
       " 'mir',\n",
       " 'mile',\n",
       " 'marker',\n",
       " 'south',\n",
       " 'mooresville',\n",
       " 'iredell',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'congestion',\n",
       " 'pm',\n",
       " 'pastor',\n",
       " 'scene',\n",
       " 'accident',\n",
       " 'owner',\n",
       " 'range',\n",
       " 'rover',\n",
       " 'mom',\n",
       " 'get',\n",
       " 'home',\n",
       " 'fast',\n",
       " 'wished',\n",
       " 'mom',\n",
       " 'accident',\n",
       " 'truck',\n",
       " 'spilt',\n",
       " 'mayonnaise',\n",
       " 'horrible',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'past',\n",
       " 'sunday',\n",
       " \"i'm\",\n",
       " 'finally',\n",
       " 'able',\n",
       " 'get',\n",
       " 'around',\n",
       " 'thank',\n",
       " 'god',\n",
       " 'wait',\n",
       " 'see',\n",
       " 'pissed',\n",
       " 'donnie',\n",
       " 'tell',\n",
       " 'another',\n",
       " 'accident',\n",
       " 'truckcrash',\n",
       " 'overturns',\n",
       " 'fortworth',\n",
       " 'interstate',\n",
       " 'http',\n",
       " 'co',\n",
       " 'rs',\n",
       " 'lj',\n",
       " 'qfp',\n",
       " 'click',\n",
       " 'crash',\n",
       " 'gt',\n",
       " 'http',\n",
       " 'co',\n",
       " 'ld',\n",
       " 'uniyw',\n",
       " 'k',\n",
       " 'accident',\n",
       " 'ashville',\n",
       " 'us',\n",
       " 'sb',\n",
       " 'sr',\n",
       " 'traffic',\n",
       " 'http',\n",
       " 'co',\n",
       " 'hylmo',\n",
       " 'wgfi',\n",
       " 'carolina',\n",
       " 'accident',\n",
       " 'motorcyclist',\n",
       " 'dies',\n",
       " 'crash',\n",
       " 'car',\n",
       " 'crossed',\n",
       " 'median',\n",
       " 'motorcycle',\n",
       " 'rider',\n",
       " 'traveling',\n",
       " 'http',\n",
       " 'co',\n",
       " 'p',\n",
       " 'lzrlmy',\n",
       " 'fyi',\n",
       " 'cad',\n",
       " 'fyi',\n",
       " 'accident',\n",
       " 'property',\n",
       " 'damage',\n",
       " 'nhs',\n",
       " 'piner',\n",
       " 'rd',\n",
       " 'horndale',\n",
       " 'dr',\n",
       " 'rt',\n",
       " 'naayf',\n",
       " 'first',\n",
       " 'accident',\n",
       " 'years',\n",
       " 'turning',\n",
       " 'onto',\n",
       " 'chandanee',\n",
       " 'magu',\n",
       " 'near',\n",
       " 'mma',\n",
       " 'taxi',\n",
       " 'rammed',\n",
       " 'halfway',\n",
       " 'turned',\n",
       " 'everyone',\n",
       " 'conf',\n",
       " 'accident',\n",
       " 'left',\n",
       " 'lane',\n",
       " 'blocked',\n",
       " 'manchester',\n",
       " 'rt',\n",
       " 'nb',\n",
       " 'eddy',\n",
       " 'rd',\n",
       " 'stop',\n",
       " 'go',\n",
       " 'traffic',\n",
       " 'back',\n",
       " 'nh',\n",
       " 'delay',\n",
       " 'mins',\n",
       " 'traffic',\n",
       " 'accident',\n",
       " 'property',\n",
       " 'damage',\n",
       " 'piner',\n",
       " 'rd',\n",
       " 'horndale',\n",
       " 'dr',\n",
       " 'accident',\n",
       " 'http',\n",
       " 'co',\n",
       " 'oia',\n",
       " 'fxi',\n",
       " 'gm',\n",
       " 'fyi',\n",
       " 'cad',\n",
       " 'fyi',\n",
       " 'accident',\n",
       " 'property',\n",
       " 'damage',\n",
       " 'wpd',\n",
       " 'th',\n",
       " 'st',\n",
       " 'pm',\n",
       " 'traffic',\n",
       " 'accident',\n",
       " 'injury',\n",
       " 'willis',\n",
       " 'foreman',\n",
       " 'rd',\n",
       " 'http',\n",
       " 'co',\n",
       " 'vckit',\n",
       " 'edev',\n",
       " 'aashiqui',\n",
       " 'actress',\n",
       " 'anu',\n",
       " 'aggarwal',\n",
       " 'near',\n",
       " 'fatal',\n",
       " 'accident',\n",
       " 'http',\n",
       " 'co',\n",
       " 'otfp',\n",
       " 'lqw',\n",
       " 'suffield',\n",
       " 'alberta',\n",
       " 'accident',\n",
       " 'https',\n",
       " 'co',\n",
       " 'bptmlf',\n",
       " 'p',\n",
       " 'mile',\n",
       " 'backup',\n",
       " 'south',\n",
       " 'accident',\n",
       " 'blocking',\n",
       " 'right',\n",
       " 'lanes',\n",
       " 'exit',\n",
       " 'langtree',\n",
       " 'rd',\n",
       " 'consider',\n",
       " 'nc',\n",
       " 'nc',\n",
       " 'nc',\n",
       " 'alternate',\n",
       " 'accident',\n",
       " 'changed',\n",
       " 'life',\n",
       " 'help',\n",
       " 'determine',\n",
       " 'options',\n",
       " 'financially',\n",
       " 'support',\n",
       " 'life',\n",
       " 'care',\n",
       " 'plans',\n",
       " 'going',\n",
       " 'treatment',\n",
       " 'breaking',\n",
       " 'deadly',\n",
       " 'motorcycle',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'happened',\n",
       " 'hagerstown',\n",
       " 'today',\n",
       " \"i'll\",\n",
       " 'details',\n",
       " 'state',\n",
       " 'whag',\n",
       " 'flowri',\n",
       " 'marinading',\n",
       " 'accident',\n",
       " 'car',\n",
       " 'even',\n",
       " 'week',\n",
       " 'got',\n",
       " 'fucking',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'mfs',\n",
       " \"can't\",\n",
       " 'fucking',\n",
       " 'drive',\n",
       " 'norwaymfa',\n",
       " 'bahrain',\n",
       " 'police',\n",
       " 'previously',\n",
       " 'died',\n",
       " 'road',\n",
       " 'accident',\n",
       " 'killed',\n",
       " 'explosion',\n",
       " 'https',\n",
       " 'co',\n",
       " 'gfjfgtodad',\n",
       " 'still',\n",
       " 'heard',\n",
       " 'church',\n",
       " 'leaders',\n",
       " 'kenya',\n",
       " 'coming',\n",
       " 'forward',\n",
       " 'comment',\n",
       " 'accident',\n",
       " 'issue',\n",
       " 'disciplinary',\n",
       " 'measures',\n",
       " 'arrestpastornganga',\n",
       " 'aftershock',\n",
       " 'delo',\n",
       " 'scuf',\n",
       " 'ps',\n",
       " 'live',\n",
       " 'game',\n",
       " 'cya',\n",
       " 'man',\n",
       " 'drive',\n",
       " 'effort',\n",
       " 'gets',\n",
       " 'painful',\n",
       " 'man',\n",
       " 'win',\n",
       " 'roger',\n",
       " 'bannister',\n",
       " 'ir',\n",
       " 'icemoon',\n",
       " 'aftershock',\n",
       " 'http',\n",
       " 'co',\n",
       " 'ynxnvvkcda',\n",
       " 'djicemoon',\n",
       " 'dubstep',\n",
       " 'trapmusic',\n",
       " ...]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "# Remove all stopwords, punctuation, and numbers\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Create new column\n",
    "new_list = []\n",
    "\n",
    "for i in range(len(train.text)):\n",
    "    token_pattern = nltk.regexp_tokenize(train.text[i], pattern)\n",
    "    token_pattern_lower = [word.lower() for word in token_pattern]\n",
    "    token_pattern_lower_stopless = [word for word in token_pattern_lower if word not in stopwords_list]\n",
    "    new_list.append(token_pattern_lower_stopless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to df\n",
    "train['cleaned_text'] = new_list\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                           new_text  \n",
       "0       1  [deeds, reason, earthquake, may, allah, forgiv...  \n",
       "1       1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2       1  [residents, asked, shelter, place, notified, o...  \n",
       "3       1  [people, receive, wildfires, evacuation, order...  \n",
       "4       1  [got, sent, photo, ruby, alaska, smoke, wildfi...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_stopped</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[13,000, people, receive, #, wildfires, evacua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_lower  \\\n",
       "0       1  our deeds are the reason of this #earthquake m...   \n",
       "1       1             forest fire near la ronge sask. canada   \n",
       "2       1  all residents asked to 'shelter in place' are ...   \n",
       "3       1  13,000 people receive #wildfires evacuation or...   \n",
       "4       1  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "                                        text_stopped  \\\n",
       "0  our deeds are the reason of this #earthquake m...   \n",
       "1             forest fire near la ronge sask. canada   \n",
       "2  all residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [Our, Deeds, are, the, Reason, of, this, #, ea...  \n",
       "1   [Forest, fire, near, La, Ronge, Sask, ., Canada]  \n",
       "2  [All, residents, asked, to, 'shelter, in, plac...  \n",
       "3  [13,000, people, receive, #, wildfires, evacua...  \n",
       "4  [Just, got, sent, this, photo, from, Ruby, #, ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenize didn't work\n",
    "from nltk.tokenize import word_tokenize\n",
    "train['tokenized_text'] = train['text'].apply(word_tokenize) \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_stopped</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>token_text_stopped</th>\n",
       "      <th>token_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #, ea...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #, ea...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #eart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>[All, residents, asked, to, ', shelter, in, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[13,000, people, receive, #, wildfires, evacua...</td>\n",
       "      <td>[13,000, people, receive, #, wildfires, evacua...</td>\n",
       "      <td>[13,000, people, receive, #wildfires, evacuati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #, ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #, ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #Al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_lower  \\\n",
       "0       1  our deeds are the reason of this #earthquake m...   \n",
       "1       1             forest fire near la ronge sask. canada   \n",
       "2       1  all residents asked to 'shelter in place' are ...   \n",
       "3       1  13,000 people receive #wildfires evacuation or...   \n",
       "4       1  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "                                        text_stopped  \\\n",
       "0  our deeds are the reason of this #earthquake m...   \n",
       "1             forest fire near la ronge sask. canada   \n",
       "2  all residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Our, Deeds, are, the, Reason, of, this, #, ea...   \n",
       "1   [Forest, fire, near, La, Ronge, Sask, ., Canada]   \n",
       "2  [All, residents, asked, to, 'shelter, in, plac...   \n",
       "3  [13,000, people, receive, #, wildfires, evacua...   \n",
       "4  [Just, got, sent, this, photo, from, Ruby, #, ...   \n",
       "\n",
       "                                  token_text_stopped  \\\n",
       "0  [Our, Deeds, are, the, Reason, of, this, #, ea...   \n",
       "1   [Forest, fire, near, La, Ronge, Sask, ., Canada]   \n",
       "2  [All, residents, asked, to, 'shelter, in, plac...   \n",
       "3  [13,000, people, receive, #, wildfires, evacua...   \n",
       "4  [Just, got, sent, this, photo, from, Ruby, #, ...   \n",
       "\n",
       "                                        token_tweets  \n",
       "0  [Our, Deeds, are, the, Reason, of, this, #eart...  \n",
       "1   [Forest, fire, near, La, Ronge, Sask, ., Canada]  \n",
       "2  [All, residents, asked, to, ', shelter, in, pl...  \n",
       "3  [13,000, people, receive, #wildfires, evacuati...  \n",
       "4  [Just, got, sent, this, photo, from, Ruby, #Al...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TweetTokenizer didn't work either\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "train['token_tweets'] = train['text'].apply(tt.tokenize)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
